\subsection{Loading the data}
Because CouchDB doesn't support the idea of cascade joins (as described by \cite{chandar2010}), data scrubbing such as filtering and grade-symbol-to-percent translations need to be implemented either before data is sent to CouchDB, or in the index building phase. In interest of speeding up the index-building (by far the most time consuming process in this project) filtering is implemented in the \textit{nETL} software, while logical data processing is handled in the index-building (where documents can be transformed easily via \textit{JavaScript} as directed in the index-building functions).

The extraction, transformation and loading of event and grade entities become practically identical in this case, and a single line from either CSV follows a standard transformation process of:

\[Extract line
    => JSON object
    => Filter out objects
    => Add type\_ attribute
    => whitelist wanted fields
    => load to CouchDB\]

Using \textit{nETL}, the above ETL pipeline is achieved via the following configuration format:

\begin{minted}{json}
[{
    "ID": "<name of configuration>",
    "Extraction": {
        "Name": "FLATFILE",
        "path": "path/to/file.csv",
        "skipHeaderRows": 1,
        "bufferSize": 65536,
        "batchSize": 30000,
        "startFrom": 0,
        "afterTaskRunCBs": []
    },
    "Transformations": [{
            "Name": "TEXT_LINE_TO_OBJ",
            "attributeNames": "list,of,header,values",
            "delimiter": ",",
            "textQualifier": "\"",
            "escapeChar": "\\",
            "afterTaskRunCBs": []
        },
        {
            "Name": "FILTER",
            "filterOn": {
                "field1": ["<allowed val 1>", "<allowed val 2>", "<etc>"],
                "field2": ["<allowed val 1>", "<allowed val 2>", "<etc>"]
            },
            "afterTaskRunCBs": []
        },
        {
            "Name": "CREATE_OBJ_FIELD",
            "newAttributes": [
                ["type_", "<entity type>"]
            ],
            "afterTaskRunCBs": []
        },
        {
            "Name": "WHITELIST",
            "allowedAttributes": ["list", "of", "header", "values", "type_"],
            "afterTaskRunCBs": []
        }
    ],
    "Load": {
        "Name": "COUCHDB",
        "username": "<admin>",
        "password": "<password>",
        "server": "localhost",
        "port": 5984,
        "ssl": false,
        "database": "<db name>",
        "afterTaskRunCBs": []
    }
}]
\end{minted}

TODO: Look at time complexity of the nETL modules used

\subsection{MapReduce indexes}
The idea of MapReduce allows for a varied and wide approach to data-querying in general. Application is limited somewhat in CouchDB due to it's implementation as a means of calculating a B+tree. As such it's easy to shoot yourself in the foot when building CouchDB MapReduce indexes without understanding the nature of how those indexes are stored or calculated. Also, due to the limitation of poor custom reduce function performance as mentioned previously, it is best to use built-in reduce functions, meaning that joining documents in couchDB effectively boils down to indexing different entities to a common output format via a \textit{map} function. Considering that a single \textit{map} function is used to process all documents in a database, this function should handle different cases for different entities. As mentioned previously, entity classification within the \textit{map} function is possible via the type\_ attribute that is appended to every object within the transformations performed by the \textit{nETL} app.

At the time of index calculation it is possible to group objects by common keys, but it is not possible to process those grouped keys unless you use a reduce function, in which case only simple metrics are supported. An initial attempt to produce a \textit{map} index of the form:

\begin{minted}{json}
[
    {"key": 1, "value": {"semster": 1, "grade": 67} },
    {"key": 1, "value": {"semster": 1} },
    {"key": 1, "value": {"semster": 2, "grade": 56} },
    {"key": 1, "value": {"semster": 2, "grade": 98} },
    {"key": 1, "value": {"semster": 1} },
    {"key": 1, "value": {"semster": 2} },
]
\end{minted}

And reduce grouped result (allowing for \mintinline{javascript}{rereduce=true}) via the following function:

\begin{minted}{javascript}
function(keys, values, rereduce) {
    // Return object
    var r = {
        eCountS1: 0,
        eCountS2: 0,
        gCountS1: 0,
        gCountS2: 0,
        gNormAvgS1: 0,
        gNormAvgS2: 0
    };
    if (rereduce) {
        values.forEach(function(item) {
            r.eCountS1 += item.eCountS1;
            r.eCountS2 += item.eCountS2;
            r.gCountS1 += item.gCountS1;
            r.gCountS2 += item.gCountS2;
            r.gNormAvgS1 += (item.gCountS1 * item.gNormAvgS1);
            r.gNormAvgS2 += (item.gCountS2 * item.gNormAvgS2);
        });
    } else {
        values.forEach(function(item) {
            // No item.grade means it's an event
            if (!item.grade) {
                if (item.semester === 1) {
                    r.eCountS1++
                } else {
                    r.eCountS2++
                };
                return;
            };
            // If it's a grade
            if (item.semester === 1) {
                r.gCountS1++;
                r.gNormAvgS1 += (r.gCountS1 === 1) ? item.grade : (item.gNormAvgS1 * item.grade);
            } else {
                r.gCountS2++;
                r.gNormAvgS2 += (r.gCountS2 === 1) ? item.grade : (item.gNormAvgS2 * item.grade);
            };
        });
    };
    return r;
};
\end{minted}

After almost 10 hours of waiting for the index to build, the calculation was canceled. it's hard to know what the bottlenecks of calculating the index using this method are; Jan Lehnardt mentioned (see \ref{appendix:slack-1-nov}) that the majority of the work done in the indexing process is by the \textit{map} process. However, it should be noted that per an student ID there could be as many as 8 000 objects in the \textit{value} array, so that could also be a factor. In terms of time complexity, this query superficially seems fine - approximately  $ O(n^2) $ TODO.

On "re-imagining" the MapReduce query to make use of CouchDB's built-in \_sum function to aggregate several metrics, the map function needs to output \textit{key:value} pairs of a slightly different form:

\begin{minted}{json}
[
    { "key": 1, "value": ["<iEvCountS1>", "<iEvCountS2>", "<iGrCountS1>", "iGrCountS2", "<fGrTotS1>", "<fGrTotS2>"] },
    { "key": 1, "value": [0, 1, 0, 0, 0, 0] },
    { "key": 1, "value": [0, 1, 0, 0, 0, 0] },
    { "key": 1, "value": [1, 0, 0, 0, 0, 0] },
    { "key": 1, "value": [0, 0, 0, 1, 0, 45] },
    { "key": 1, "value": [0, 0, 1, 0, 76, 0] },
    { "key": 2, "value": [0, 0, 1, 0, 50, 0] },
]
\end{minted}

CouchDB's built-in \_sum \textit{reduce} aggregates the above result to:

\begin{minted}{json}
[
    { "key": 1, "value": [1, 2, 1, 1, 76, 45] },
    { "key": 2, "value": [0, 0, 1, 0, 50, 0] },
]
\end{minted}

which is a suitable join for grade analysis. The full \textit{Map} and \textit{Reduce} functions to achieve this are described below and is approximately $ O(n) $... TODO. Some filtering is done in the \textit{Map} function that could just as easily have been applied to the data within the \textit{nETL} process. Logic on handling non-numerical percents as described previously is handled within the map function.

\begin{minted}{javascript}
// Map function
/**
 * outputs: key:[eCountS1, eCountS2, gCountS1, gCountS2, gSumAvgS1, gSumAvgS2]
 * @param {Object} doc CouchDB document passed to Map function
 */
function(doc) {
    var output = [0, 0, 0, 0, 0, 0];
    var disallowedPercents = ['ATT', 'DE', 'GIP', 'LOA', 'OS', 'OSS', 'PA', 'SAT', 'UNS', ''];
    var allowedSuffixes = ["S", "F", "W", "H", "L", "P"];
    switch (doc.type_) {
        case 'courseGrade':
            var semester = (doc.CourseSuffix || 'N').toUpperCase();
            if (allowedSuffixes.indexOf(semester) >= 0) {
                var p = doc.Percent || '';
                // If p not a number, try convert
                if (typeof p !== 'number') {
                    if (typeof p !== 'string') return;
                    var newP = p.toUpperCase().trim();
                    if (disallowedPercents.indexOf(p) >= 0) return;
                    switch (newP) {
                        case 'AB':
                            p = 40;
                            break;
                        case 'F':
                            p = 40;
                            break;
                        case 'DPR':
                            p = 20;
                            break;
                        case 'INC':
                            p = 20;
                            break;
                        case 'UF':
                            p = 30;
                            break;
                        case 'UP':
                            p = 50;
                            break;
                        default:
                            p = parseFloat(p.substring(0, p.length - 1));
                            if (isNaN(p)) return;
                            break;
                    };
                };
                if (semester === 'F' || semester === 'L') {
                    output[2] = 1;
                    output[4] = p;
                } else if (semester === 'S' || semester === 'P') {
                    output[3] = 1;
                    output[5] = p;
                } else {
                    output[2] = 1;
                    output[3] = 1;
                    output[4] = p;
                    output[5] = p;
                };
                emit(doc.anonIDnew, output);
            };
            break;
        case 'vulaEvent':
            var date = (new Date(doc.event_date)).getTime();
            var midDate = 1468792800000 // Sunday, July 17, 2016 10:00:00 PM
            var semester = (date - midDate >= 0) ? 2 : 1;
            if (semester === 1) {
                output[0] = 1;
            } else {
                output[1] = 1;
            };
            emit(doc.uct_id, output);
            break;
        default:
            break;
    };
};

// Reduce function
_sum // Built-in function
\end{minted}

\subsubsection*{Expanding the Map function}
In the interest of further pushing CouchDB's querying capabilities, a second index was configured to add the \textit{demographic} entity to the joined aggregation and the map function above was expanded to deal with the additional entity:

\begin{minted}{javascript}
/**
 * outputs: key:[<list of 10 numbers>]
 * @param {Object} doc CouchDB document passed to Map function
 */
function(doc) {
    var output = [
        0, // eCountS1
        0, // eCountS2

        0, // gCountS1
        0, // gCountS2
        0, // gSumAvgS1
        0, // gSumAvgS2

        0, // dCount
        0, // nbtAL
        0, // nbtQL
        0 // nbtMath
    ];

    // Checks number
    function processScore(score) {
        var r = parseFloat(score);
        return (!r || isNaN(r)) ? 0 : r;
    };

    // Create output
    switch (doc.type_) {
        case 'courseGrade':
            // ...
            emit(doc.anonIDnew, output);
            break;

        case 'vulaEvent':
            // ...
            emit(doc.uct_id, output);
            break;

        case 'demographic':
            output[6] = 1; // count
            var nbtAL = processScore(doc["NBT AL Score"]);
            var nbtQL = processScore(doc["NBT QL Score"]);
            var nbtMath = processScore(doc["NBT Math Score"]);
            output[7] = nbtAL;
            output[8] = nbtQL;
            output[8] = nbtMath;
            emit(doc.anonIDnew, output);
            break;

        default:
            break;
    };
};
\end{minted}

Because within the demographic data a particular student ID only appears once, it's possible to take into account non-numerical values within the aggregation. For example, and taking into account that the map output needs to be a list of \textit{numbers}, "sex" can be mapped as \textit{Female:1}, \textit{Male:2}, \textit{etc:..} with one index in the map output list reserved for description of sex. Population groups could be mapped in a similar way. However, CouchDB's MapReduce implementation does limit the extent to which such data could be queried. A query that can be fairly easily expressed in \textit{SQL}:

\begin{minted}{sql}
SELECT
    D.StudentID,
    G.CourseID,
    COUNT(E.Event),
    AVG(G.Grades)
FROM Demographics D
LEFT JOIN Grades G ON G.StudentID = D.StudentID
LEFT JOIN Events E ON E.StudentID = D.StudentID
GROUP BY
    D.StudentID,
    G.CourseID
\end{minted}

cannot be achieved as easily in couchDB since it would not be possible to emit the course ID itself in Map function list output and summing some kind of mapping to a course ID makes no sense. Instead it is necessary to work in a roundabout way, where the map function would either output a much longer list (corresponding to the total number of course grades). In theory CouchDB should be able to handle different output formats of the map function in which case this query would be fine. In practice, however (as has been discussed above), using anything other than built-in reduce functions cripples CouchDB's index building facility and so isn't a good or usable solution.

\subsection{Index retrieval}
Due to the nature of B+tree indexes in CouchDB retrieving view data is very quick - this is the benefit of CouchDB's MapReduce implementation over non-indexed output such as Hadoop. The view data is formatted as a JSON array of \textit{[key,value]} pairs. To use the view data outside of viewing it in a browser, a translation step is required since CouchDB doesn't offer tool to export or save output. For the purposes of this project output is required in the \textit{CSV} format so as to facilitate further data analysis using stats programs, Excel, saving the output in a data warehouse, etc.

Converting CouchDB index output to \textit{CSV} is possible in this project using the \textit{nETL} application. Such a \textit{task} involves an extraction from CouchDB's \textit{:db/\_view/viewName?reduce=true\&group=true} HTTP endpoint, a translation from JSON documents to CSV rows and a \textit{loading} process to a flatfile destination. Such a configuration might look as indicated below. To achieve this a \textit{COUCH\_INDEX} module needs to be written and loaded into \textit{nETL}. The \textit{FlATFILE} module already exists for purposes other than this project, although it's not discussed within the project itself.

\begin{minted}{json}
[{
    "ID": "<name of configuration>",
    "Extraction": {
        "Name": "COUCH_INDEX",
        "uri": "localhost:5984/msc/_design/db/_view/student-grades?group=true&reduce=true",
        "afterTaskRunCBs": []
    },
    "Transformations": [{
            "Name": "OBJ_TO_CSV",
            "delimiter": ",",
            "textQualifier": "\"",
            "escapeChar": "\\",
            "afterTaskRunCBs": []
        }
    ],
    "Load": {
        "destinationType": "FLATFILE",
        "skipBlankLines": true,
        "path": "path/to/download/results.csv",
        "afterTaskRunCBs": []
    }
}]
\end{minted}

As of CouchDB 2.1 there is the concept of a \textit{list} functions, although as noted previously and confirmed by personal communication with Jan Lehnardt the current CouchDB PMC chair (see \ref{appendix:slack-2-nov}), while this feature is not going to be removed it may fall by the wayside without additional support. But with support in the current implementation of CouchDB they represent a more time-effective of retrieving information from CouchDB indexes than using the \textit{nETL} app - and this is the solution that this project show cases. \textit{List} functions, like \textit{MapReduce} indexes, are defined in design documents. The functions iterate the rows of an index to a user in the specified format along with any transformations. Since index results are guaranteed to be ordered by key, this is powerful and allows for combining result steps of documents for adjacent keys if required. In this project a list function is simply used to enable users to download the values produced by the \textit{student-grades} view in CSV format, and is defined be the code below. This function is called via the URI \textit{host:5984/db/\_design/name/\_list/listname/viewname?group=true\&reduce=true}. All of the parameters available to the index retrieval endpoint (\textit{\_view/...}) are available when the view is called by the list function, including specifying an array of keys if only a subset of the index results are required. Time complexity of the list function is approximately $ O(n) $ TODO.

\begin{minted}{javascript}
function(head, req) {
    provides('csv', function() {
        var headers = "Student ID (anonymized),\
        Presence Events S1,\
        Presence Events S2,\
        Grade Count S1,\
        Grade Count S2,\
        Grade Sum S1,\
        Grade Sum S2,\
        Grade Avg S1,\
        Grade Avg S2";
        send(headers);

        while (row = getRow()) {
            var id = row.key;
            var value = row.value;
            var eCountS1 = value[0];
            var eCountS2 = value[1];
            var gCountS1 = value[2];
            var gCountS2 = value[3]
            var gSumS1 = value[4];
            var gSumS2 = value[5];
            var gAvgS1 = (gCountS1 > 0) ? (gSumS1 / gCountS1) : "";
            var gAvgS2 = (gCountS2 > 0) ? (gSumS2 / gCountS2) : "";
            var line = "\n" + id + "," + eCountS1 + "," + eCountS2 + "," + gCountS1 + "," + gCountS2 + "," + gSumS1 + "," + gSumS2 + "," + gAvgS1 + "," + gAvgS2;
            send(line);
        };
    });
};
\end{minted}