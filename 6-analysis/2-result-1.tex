\section{Result 1}
Assessing the relationship between student benchmarks and CSC1015F grades for all students requires a join of the demographic (FU) data with Grade data. For this analysis the \textit{nETL} configuration (see \ref{netl-run1-config}) specifies two source CSVs - ``FU-CombinedGrades-2016Reg.csv'' (FU data) and ``CombinedGrades.csv'' (Grade data). \textit{nETL} execution is discusses in terms of each CSV source below, followed by a discussion of the configuration to run the CouchDB MapReduce calculation and retrieval of the result.

\subsection*{Grade data \textit{nETL} workflow}
\begin{enumerate}
    \item Batches of 10 000 lines are extracted iteratively (and sequentially) as an array of lines
    \item Within each batch, each line is converted to a JSON object, transforming the batch into an array of objects. These objects each have the following fields: ``DownloadedDate'', ``RegAcadYear'', ``RegTerm'', ``anonIDnew'', ``RegProgram'', ``RegCareer'', ``Degree'', ``DegreeDescr'', ``Subject'', ``Catalog.'', ``Course'', ``CourseSuffix'', ``Session'', ``Percent'', ``Symbol'', ``UnitsTaken'', ``CourseID'', ``CourseDescr'', ``CourseCareer'', ``Faculty'', ``Dept'', ``MaximumCrseUnits'', ``CourseCount'', ``CourseLevel'', ``CESM'', ``Sub-CESM''
    \item The array of objects is filtered via whitelising objects on two fields: 1) ``RegCareer'' - only the value ``UGRD'' is considered. 2) ``Course'' - only the value ``CSC1015F'' is considered. As a result the resultant array (the batch) contains a reduced number of objects
    \item A field is added to each object in the batch (``type_'') and give the value ``courseGrade'' (this allows for logically tracking the type of entity that each document represents)
    \item Superfluous object fields are removed via a whitelisting process, resulting in a batch (an array) of objects with the fields: ``"type_"'', ``"Course"'', ``"RegAcadYear"'', ``"anonIDnew"'', ``"Percent"''
    \item Each batch is loaded into CouchDB using the \textit{\_bulk\_docs} endpoint (as discussed previously), and the next batch is extracted on a success message from CouchDB
\end{enumerate}

\subsection*{FU data \textit{nETL} workflow}
\begin{enumerate}
    \item Batches of 10 000 lines are extracted iteratively (and sequentially) as an array of lines
    \item Within each batch, each line is converted to a JSON object, transforming the batch into an array of objects. These objects each have the following fields: ``anonIDnew'', ``Career'', ``Citizenship Residency'', ``SA School'', ``Eng Grd12 Fin Rslt'', ``Math Grd12 Fin Rslt'', ``Mth Lit Grd12 Fin Rslt'', ``Adv Mth Grd12 Fin Rslt'', ``Phy Sci Grd12 Fin Rslt'', ``NBT AL Score'', ``NBT QL Score'', ``NBT Math Score'', ``RegAcadYear''
    \item The array of objects is filtered via whitelising objects on three fields: 1) ``Career'' - the values ``UGRD'', ``First Year'', ``Second Year'', and ``Third Year'' are considered. 2) ``Citizenship Residency'' - the values ``SA Citizen'', ``Permanent Resident'', ``C'', ``P'' are considered. 3) ``anonIDnew'' - a list of student Ids for students that attended CSC1015F at any time during their undergraduate careers. This list was prepared manually for the purposes of this project
    \item A field is added to each object in the batch (``type_'') and give the value ``demographic'' (this data is actually a subset of general demographic data)
    \item Superfluous object fields are removed via a whitelisting process, resulting in a batch (an array) of objects with the fields: ``type_'', ``anonIDnew'', ``Eng Grd12 Fin Rslt'', ``Math Grd12 Fin Rslt'', ``Mth Lit Grd12 Fin Rslt'', ``Adv Mth Grd12 Fin Rslt'', ``Phy Sci Grd12 Fin Rslt'', ``NBT AL Score'', ``NBT QL Score'', ``NBT Math Score'', ``RegAcadYear''
    \item Each batch is loaded into CouchDB using the \textit{\_bulk\_docs} and the next batch extracted
\end{enumerate}

\subsection*{The MapReduce function}
To maintain the resolution that exists within the Grade data, that is; \textit{results of a particular student in a particular year for a particular course}, the map function is configured to emit a tuple - [studentID, courseCode, year] - for keys. Compound keys are discussed previously, but effectively they allow for a configurable level of grouping values output by the map task - that is values can either by grouped by studentID (for an analysis of students averaged over all courses and all years), grouped by studentID and courseCode (to average results for repeated courses), or grouped by studentID, courseCode and year for the most granular result possible with the source data. The benefit of emitting compound keys as keys is that different groupings can be taken without recalculation of indexes. Other groupings are obviously possible if the key tuple was re-ordered. Specification for the value output is also a tuple of the form [float, float, float, float, float, float, float, float, float]. A key to what each index in the tuples represents is shown in \ref{grades-join-demographics-output}.

The map function for this analysis is shown in \ref{result-1-map}. Each document passed to the map function is treated according to the logic shown in the activity diagram in Figure \ref{result-1-map-fn}.

\begin{figure}[ht]
    \centering
    \begin{mdframed}
        \centering
        \includegraphics[scale=0.35]{./resources/figures/result-1-activity-diagram.png}
    \end{mdframed}
    \caption[Result 1 Map function]{\textbf{Figure \ref{result-1-map-fn}: Activity diagram showing logic Map function logic for Result 1.} todo:  blah blah}
    \label{result-1-map-fn}
\end{figure}