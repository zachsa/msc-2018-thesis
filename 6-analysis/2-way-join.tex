\section{2-Way Join}
An initial analysis comparing the correlation between Grade and Benchmark data requires a 2-way join between the Grades and Benchmarks datasets. To achieve this, two nETL tasks were run to extract the CSV data (the ``Grades.CSV'' and ``Benchmarks.CSV'' files) and load rows from these CSV files into CouchDB as documents of type ``grade'' and ``benchmark'' respectively. The JSON configuration file in which both these tasks are defined is included in the appendix at \ref{netl-tasks-1-2-config}. Following loading the data from the CSVs into CouchDB, a Map function is used to produce an index of the CouchDB documents sorted by Student ID, with the guarantee that for every unique student id documents are ordered by type; demographic documents are sorted before Grade documents for for any given student. Knowing the sorted order of documents via the view-index allows for performing the join on data-retrieval. In this retrieval (and joining) is performed via a CouchDB List function (discussed below), with the output in CSV format.

\subsection{nETL Configuration}
The ETL processing of Benchmark data involves an iterative approach of first reading a batch of 10 000 lines from the CSV, performing transformations on each line in the batch, and then loading each batch into CouchDB. On notification that a single batch is loaded successfully into CouchDB, a further 10 000 lines are read from the CSV and processed in the same way. This process continues until the entire CSV has been read and loaded into CouchDB. Batches are loaded into CouchDB via the \textit{\_bulk\_docs}. A list of the progression of transformations applied to each line extracted from each CSV is shown below:

\subsubsection{Task 1 Transformations (Grades)}
\begin{enumerate}
    \item A line is converted into a JavaScript object (which relates directly to the JSON format of CouchDB documents) with the fields:
          \begin{itemize}
              \item DownloadedDate
              \item RegAcadYear
              \item RegTerm
              \item anonIDnew
              \item RegProgram
              \item RegCareer
              \item Degree
              \item DegreeDescr
              \item Subject
              \item Catalog.
              \item Course
              \item CourseSuffix
              \item Session
              \item Percent
              \item Symbol
              \item UnitsTaken
              \item CourseID
              \item CourseDescr
              \item CourseCareer
              \item Faculty
              \item Dept
              \item MaximumCrseUnits
              \item CourseCount
              \item CourseLevel
              \item CESM
              \item Sub-CESM
          \end{itemize}
    \item Lines (now in object form) are filtered on the ``RegCareer'' and ``Course'' fields, where grades achieved for the CSC1015F course taken by students registered as undergrads are considered. Lines that don't meet this attribute are discarded and no further transformations are applied to these line.
    \item An attribute (``type\_'') is then added to each line (that weren't removed in filtering step), and given the value ``grade'' to identify each object as a line of the Grade entity type.
    \item Line attributes are whitelisted. The resultant lines each have the the following attributes:
          \begin{itemize}
              \item type\_
              \item Course
              \item RegAcadYear
              \item anonIDnew
              \item Percent
          \end{itemize}
\end{enumerate}

\subsubsection{Task 2 Transformations (Benchmarks)}
\begin{enumerate}
    \item A line is converted into a JavaScript object with the fields:
          \begin{itemize}
              \item anonIDnew
              \item Career
              \item Citizenship Residency
              \item SA School
              \item Eng Grd12 Fin Rslt
              \item Math Grd12 Fin Rslt
              \item Mth Lit Grd12 Fin Rslt
              \item Adv Mth Grd12 Fin Rslt
              \item Phy Sci Grd12 Fin Rslt
              \item NBT AL Score
              \item NBT QL Score
              \item NBT Math Score
              \item RegAcadYear
          \end{itemize}
    \item Lines are filtered on the ``Career'', ``Citizenship Residency'', and ``anonIDnew'' fields. Only lines for students that attended the CSC1015F course during their undergraduate career and that are either South African citizens or permanent residents are included in the result set. The list of students that attended CSC1015 is derived from the Grade data - this is a manual process since the Grade CSV is small enough that manipulation with Microsoft Excel is possible, and this is only required once (so it's not worth automating).
    \item An attribute (``type\_'') is then added to each remaining line and given the value ``benchmark'' to identify each object as a line of the Benchmark entity type.
    \item Line attributes are whitelisted. The resultant lines each have the the following attributes:
          \begin{itemize}
              \item type\_
              \item anonIDnew
              \item Eng Grd12 Fin Rslt
              \item Math Grd12 Fin Rslt
              \item Mth Lit Grd12 Fin Rslt
              \item Adv Mth Grd12 Fin Rslt
              \item Phy Sci Grd12 Fin Rslt
              \item NBT AL Score
              \item NBT QL Score
              \item NBT Math Score
              \item RegAcadYear
          \end{itemize}
\end{enumerate}

\subsection{MapReduce Functions}
The map function for this analysis is included in the appendix (see \ref{result-1-map}). Each document passed to the map function is treated according to the logic shown in the activity diagram in Figure \ref{result-1-map-fn}. That is, on Map function execution the ``type\_'' attribute is checked. If the document is a line of the Grades entity, then the key [Student ID, year] is emitted along with a single number for the value - the percent achieved for the course. If the document is a line of the Benchmarks entity, then the key [student ID, 0] is emitted along with an ordered list of 8 values corresponding to values for the fields in the Benchmarks.CSV file:

\begin{itemize}
    \item Gr12 English \%
    \item Gr12 science \%
    \item Gr12 Math \%
    \item Gr 12 Math Lit \%
    \item Gr12 Adv Math \%
    \item NBT AL \%
    \item NBT QL \%
    \item NBT Math \%
\end{itemize}

Normalization of the percentage fields (i.e. ``Percent'' for the Grades entity and the test results in the Benchmarks entity) is done via a nested function within the Map function and according to the logic as discussed in that tables previously. No reduce function is used to achieve this 2-way join. This is because, theoretically, a student should only have a single set of Benchmark results and should only achieve a single grade per course per year. As such there is no need to aggregate output from the Map function (which is done via reduction) before performing the document join via the List function.

\begin{figure}[ht]
    \centering
    \begin{mdframed}
        \centering
        \includegraphics[scale=0.35]{./resources/figures/activity-diagram-1.png}
    \end{mdframed}
    \caption[Result 1 Map function]{\textbf{Figure \ref{result-1-map-fn}: Activity diagram showing logic Map function logic for Results 1 \& 2.} This logic is applied to every document during index calculation (excluding documents with an \_id of ``\_design/*'').}
    \label{result-1-map-fn}
\end{figure}

\subsection{List Function}
TODO

The list function is used to iterate over the results of the MapReduce view, and transform the JSON structure of the view return into a CSV. The list function is included in the appendix (see \ref{result-1-list}). The logic is fairly straight forward; The list function is called via HTTP, specifying the view in the URL, along with the options to group map output by key (at exact level) and to use the reduced result set. The List function first emits a row of headers, as defined in the function itself, and then iterates over the keys in the MapReduce index. For each key, the List function emits a string of comma separated values followed by a newline char according to the RFC 4180 specification. This allows for CSV's to be created and downloaded incrementally allowing for iteration over huge MapReduce indexes.

As mentioned previously List functions are likely to become deprecated in CouchDB. As such it would be better practice to replicate the logic of the List function in a node.js (or alternative) application. If this were to be done, the logic involved in producing a CSV from the MapReduce results would remain the same.