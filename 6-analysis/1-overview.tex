\section{Overview}
Producing a dataset suitable for analysis involves the workflow specified in \ref{analysis-workflow}. Effectively this is a 3 stage process, where a user configures and runs the \textit{\_nETL} application to load the data into CouchDB, and then configures a couchDB design document to produce an index and retrieve that index as a CSV. Once a CSV of the joined data has been obtained, it's easy to load the data into Excel and produce a result.

\begin{figure}[ht]
    \centering
    \begin{mdframed}
        \centering
        \includegraphics[scale=0.35]{./resources/figures/analysis-workflow.png}
    \end{mdframed}
    \caption[Analysis Workflow]{\textbf{Figure \ref{analysis-workflow}: Workflow to perform an analysis.}1) User creates a configuration file (JSON) that is loaded into the running \textit{\_nETL} service. This configuration includes instructions on which CSVs to load, which modules should be loaded to process the CSVs, and configurations for the modules. 2) Modules are loaded from a library of available modules into the \textit{\_nETL} service. 3) CSVs are loaded into the service, and transformations are applied to the CSV data as specified by the configuration in (1). 4) Data from the CSVs is loaded into CouchDB; this is also achieved via a module specified in (1). 5) A user creates a CouchDB design document, specifying the MapReduce functions, and a List function. 6) The user asks CouchDB to produce the view index as specified by the design document in (5). 7) The user retrieves the data from the view index using the list function specified in (5). 8) The user then loads the resultant CSV into Excel to produce useful metrics.}
    \label{analysis-workflow}
\end{figure}



Joining across the 3 entities (Demographics, Grades and Events), in adherence with the \textit{\_stats} function contract, requires emitting common keys in the map function on which grouping can be performed. To maintain the resolution that exists within the Grade data, that is; \textit{results of a particular student in a particular year for a particular course}, a compound key of the tuple \textless studentID, courseCode, year \textgreater is used for grouping, i.e. for every document processed by the map function, a key:value pair with a key in the form of that tuple needs to be emitted. Emitting this compound key is straightforward for grade data since each document of \textit{type\_} courseGrade has fields for all three of these values. However, neither the demographic nor the event data contains fields for 'courseCode', and student benchmarking in the demographic data are only for the year that student first registered. As such, of the required fields to output the key for joining, Demographic data only contains a 'studentID' field. Documents of \textit{type\_} 'sakaiEvent' include fields for studentId and year, but not courseCode (there is a FK field \textit{course\_id}) but it doesn't point to any field in the grade data.

To produce a key of the tuple \textless studentID, courseCode, year \textgreater for demographic data, the courseCode and year value have to be fabricated. In other words, demographic data has to be duplicated for every possible key combination on which it could be joined. In this case a single demographic document needs to be output for every course that a student can take, and then further duplicated for every year in which a student could take that course. Likewise the event data, which has fields for studentID and year, needs to be duplicated for every course that a student can take. Such an approach to joining is the basis of this analysis, which is done in iterations. Each iteration increases the volume of data processed by the map function so as to get insight in the effectiveness of this approach to joining documents. Analyses are discussed in terms of the results of each iteration. In general, each analysis involves 4 phases of data-wrangling:



Configurations used for \textit{nETL} for all the runs done while creating the analysis described below are shown in the appendix - see \ref{netl-run1-config}). Runtime results of \textit{nETL}, CouchDB indexing times, database/index storage footprints are shown in Table \ref{performance-analysis}. Initial CouchDB view calculation was performed on a local machine, but subsequently to achieving the analysis results, indexing time was compared on different cluster sizes. These times are shown in \ref{couch-indexing}. As seen in the table, increasing the cluster size reduces the time taken to index a database as per the described \textit{MapReduce} function decreases. This is as expected since dispersing documents across shards should be random enough that documents get distributed across shards uniformly (see \ref{slack-7-nov}), meaning that increasing nodes in a cluster reduces the amount of work a node must do when calculating \textit{map} output. However, it is likely that small data sets would not benefit from clustering since there is a high network overhead of sharded databases.

\section{Join of Grades/Demographics}
Creating datasets comprising grade and FU data involved filtering CSVs and loading that data into CouchDB using \textit{nETL}

For a join on the Grades and Demographics entities, the map function is configured to output key-value pairs of the form: \textless studentID, courseCode, year \textgreater : <9 element list>. A description of the 11-element value list is shown in \ref{grades-join-demographics-output}. Configuration for the \textit{nETL} task is shown in the appendix (see \ref{netl-config-grades-join-demographics}), as is the Map function and list function (see\ref{msc-design-doc}).

The list shown in \ref{grades-join-demographics-output} shows ALL the values output by a map function on the join between all three entities. For the first two runs, event information is NOT emitted.

\begin{figure}[ht]
    \centering
    \begin{minted}{javascript}
 [
    // Grade Entitty output
    "CSC1015F %",

    // Demographic Entity output
    "Gr12 Eng %", 
    "Gr12 Sci %",
    "Gr12 Mth %",
    "Gr12 Mth Lit %",
    "Gr12 Mth Adv %",
    "NBT AL %",
    "NBT QL %",
    "NBT Mth %",

    // Event entity output
    "eventCount S1", // Only included for Run 3/4
    "eventCount S2" // Only included for Run 3/4
 ]    
    \end{minted}
    \caption[2-way-join map output]{\textbf{Figure \ref{grades-join-demographics-output}: Output of map function for grades joined with demographics.} This list, shown as a JavaScript array, is the key to the map function output. In other words, the map function outputs a list of values that correspond to this list. When retrieving the view output, headers can be given back to the columns retrieved using this key. View output can be achieved via a List function (as has been done in this project), or via bespoke JavaScript code.}
    \label{grades-join-demographics-output}
\end{figure}

% Runs
\input{6-analysis/2-join-runs}

\section{join of Grades/Demographics/Events}

% Runs
\input{6-analysis/3-join-runs}
