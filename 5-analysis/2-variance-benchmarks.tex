\section{Admission-benchmarks Variance}
The admissions data contains several test scores that are used to benchmark students. These scores include:

\begin{itemize}
  \item Grade 12 results
        \begin{itemize}
          \item English
          \item Math
          \item Physical Science
        \end{itemize}
  \item NBT (national benchmark test) scores
        \begin{itemize}
          \item AL
          \item QL
          \item Math
        \end{itemize}
\end{itemize}

The data also contains Adv. Math and Math Lit scores, but these are ignored since so few of the students enrolled in CSC1015F took these courses (values of these fields are ``0''). In addition to raw test results in the admissions data, additional derived benchmarks are tested comprising aggregations of the raw scores, including:

\begin{itemize}
  \item Average of Grade 12 results (Eng/Mth/Sci)
  \item Avg of Gr 12 results with double Mth weighting \footnote{UCT previously used this benchmark as a means for evaluating incoming students \cite{sonia2018}}
  \item Avg of Gr 12 results with double Mth/Sci weighting \footnote{UCT currently uses this benchmark as a means for evaluating incoming students \cite{sonia2018}}
  \item Avg of NBT and Gr 12 scores
  \item Avg of NBT and Gr 12 scores with double Gr 12 Math weighting
  \item Avg of NBT and Gr 12 scores with double Gr 12 Math and Science weighting
\end{itemize}

Variance $(\sigma_{\overline{x}})^{2}$ and standard deviation $\sigma_{\overline{x}}$ are worked out for these methods of benchmarking incoming students across admissions data from 2014,2015 and 2016 for students that are residents of South Africa and who attended CSC1015F one or more times during the course of their undergraduate career. Data selection is performed in nETL, data aggregation is performed in the MapReduce functions, and the variance and standard deviation are calculated in the list function during data retrieval.

\subsection{ETL}
Rows are extracted from the admissions data (\mintinline{text}{Admissions (2014 - 2016).csv}) in batches of 5 000. Each row is converted to an object, and filtered by nETL on the attributes \textit{Career} and \textit{Citizenship Residency} to select rows of benchmark data for students enrolling for undergraduate, and who are citizens or permanent residents of South Africa. Then remaining objects in each batch are filtered again on the \textit{anonIDnew} attribute via nETL's dynamic filtering module; only objects that contain student numbers associated with CSC1015F grades between 2014 and 2016 are selected (a list of these students is retrieved from CouchDB during the filtering process). Remaining objects have a \textit{type\_} attribute added with the value ``benchmarks'', and then batches of objects (there are at most 5 000 objects per batch, but usually far fewer due to the filtering) are loaded into a CouchDB database. An example of a row from the admissions data serialized to a JSON string and as loaded into CouchDB is shown in Figure \ref{fig-json-admission}.

\input{5-analysis/figures/fig-json-admission}

\subsection{Index Calculation}
All the benchmark rows loaded into the CouchDB database are mapped to an index consisting of \textit{anonIDnew:[benchmarks]} key-value pairs via a map function named \texttt{variance.html} (\texttt{.html} is appended to the map function name so that the final list output is identified as HTML output by the browser). Derivative benchmarks are calculated during map function execution and output to the index as part of the list of benchmarks. Because all numbers in JavaScript are 64-bit floating-point (following the IEEE 754 standard \cite{floatingPoint}), working with rational numbers with decimal points results in peculiarities compared to expectations formed from working with a base-10-framed mindset - for example, the sum: $0.1 + 0.2 = 0.30000000000000004$. Decimals such as $0.1$ and $0.2$ cannot be accurately represented in binary format within 64-bit address space (or any finite amount of memory). As such, rounding errors occur. Quantifying the margin for such errors and handling these cases correctly is difficult \cite{Goldberg1991}, so to side-step this uncertainty an open-source library (\textit{decimal.js} \cite{decimaljs}) is used to handle arithmetic via JavaScript. CouchDB allows usage of 3rd party JavaScript libraries via implementing CommonJS module loading within the context of couchjs.exe \cite{commonJsMapFn}.

The built-in \_stats function is used to aggregate values in the view-index by benchmark type, which when used without grouping by index key results in MapReduced output of a single tuple containing an object for each benchmark used/created. MapReduce is serialized to JSON as shown in Figure \ref{fig-variance-reduce-output}. The \_stats function aggregates benchmark by describing each benchmark in terms of the sum of all students scores for that particular admissions benchmark, the count of how many students are included in the sum, the worst (min) and best (max) scores achieved for each test (or average of tests) by a student, and the sum of squares of each students scores.

\input{5-analysis/figures/fig-variance-reduce-output}

\subsection{Index Retrieval}
Variance and standard deviation are calculated directly from the reduced index output during data retrieval using a CouchDB list function, with results output in tabular form as shown in Table \ref{tbl-variance-benchmarks} (but in HTML format) with 3 columns:

\begin{itemize}
  \item \textit{Benchmark}: Possible benchmarking methods for assessing incoming students (comprising certain admissions fields / combinations of these fields)
  \item \textit{$(\sigma_{\overline{x}})^{2}$}: Variance of each benchmarking dataset
  \item \textit{$\sigma_{\overline{x}}$}: Standard deviation of each benchmarking dataset
\end{itemize}


With reference to Figure \ref{fig-variance-reduce-output} (aggregated benchmark output), variance and standard deviation is worked out according to the following formulae: \begin{spreadlines}{15pt}
  \begin{gather*}
    \intertext{\textit{Variance:}}
    (\sigma_{\overline{x}})^{2} = \frac{\sum{(x-\bar{x})^2}}{n-1}\\
    \intertext{\textit{Variance in terms of reduce (\_stats) output:}}
    (\sigma_{\overline{x}})^{2} = \frac{sumsqr}{count-1} - (\frac{sum}{count})^{2}\\
    \intertext{\textit{Standard Deviation:}}
    \sigma_{\overline{x}} = \sqrt{\frac{sumsqr}{count-1} - (\frac{sum}{count})^{2}}
  \end{gather*}
\end{spreadlines}


\input{5-analysis/tables/tbl-variance-benchmarks}