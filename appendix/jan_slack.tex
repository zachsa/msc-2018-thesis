\section{Slack conversation 2}
\label{appendix:jan_slack}
zach [3:53 PM]
at the risk of sounding like a repetitive novice... what is wrong with indexes that get bigger and bigger? Is it best to avoid them because a) there is almost always a better way of doing something? or b) they have some other effect on the CouchDB process (other than whatever overhead is required to use a larger-than-requried index)

rnewson (IRC) APP [3:57 PM]
'bigger and bigger'?

jan [4:03 PM]
@zach not sure what you mean, indexes are expected to grow with more documents

zach [4:22 PM]
writing a reduce function I sometimes get a warning that reduce output is not shrinking fast enough - in this case i can either rewrite my reduce function or turn off the setting. As you mentioned previously @jan, option 1 (rewriting) is definitely the way to go. But what is the reason for this? Is it because a reduce function that doesn't shrink output requires continuous balancing of the B+ tree which means poor performance? (i don't have a background in data structures). what are the theoretical problems of in a reduce function like this: function(keys, values, rereduce){return values (with code to do the same in the rereduce)} if there was an unlimited amount of hardrive space available.

[4:23]
I know this is a 'relational' approach.. and that there are better options. but I'm still interested in why

jan [4:49 PM]
that reduce function will copy all values from the leaves of the b-tree into the root node, and all intermediate nodes get their share of leaves copied in as well. Youâ€™re effectively stacking a reverse tree on top of the actual tree, approaching O(N^2) or worse performance and disk use.

zach [4:51 PM]
ah. thank you

jan [4:55 PM]
I.e. it subverts everything an index is meant to do