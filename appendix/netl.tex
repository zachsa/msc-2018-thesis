\section{nETL Engine}
\subsection{Sequential Batch Iterator}
\label{netl-batch-generator}
\begin{minted}{text}
const extraction;
const batches = (function*() {
    var finished = false;
    while (!finished) {
        let data = [];
        for (let i = 0; i < batchSize; i++) {
            let datum = extraction.getNext();
            if (datum.done) {
                finished = true;
                break
            };
            data.push(datum.value);
        };
        log.info("Task : " + key + " : Batch extracted : Batch size : " + data.length);
        yield data;
    };
})();

// Iteratively generate next batch
batch = batches.next();
\end{minted}

\subsection{TaskManager Constructor}
\label{netl-taskmanager-constructor}
\begin{minted}{text}
function TaskManager(e, ts, l) {
    this.tasks = {};
    this.extractions = e;
    this.transformations = ts;
    this.loads = l;
};
TaskManager.prototype.newTask = function(task) { /* ... */ };
\end{minted}

\subsection{Main Application Module}
\label{netl-application-module}
\begin{minted}{text}
(function() {
    const _extractions = {};
    const _transformations = {};
    const _loads = {};        
    const _taskManager = new TaskManager(_extractions, _transformations, _loads);
    function _loadExtractionModule(eModule){/* ... */};
    function _loadTransformationModule(tModule){/* ... */};
    function _loadLoadModule(lModule){/* ... */};
    return {
        taskManager: _taskManager,
        loadExtractionModule: _loadExtractionModule,
        loadTransformationModule: _loadTransformationModule,
        loadLoadModule: _loadLoadModule
    };
})();
\end{minted}


\subsection{Recursive ETL Iteration}
\label{netl-recursive-iterator}
\begin{minted}{text}
const batches; // Assigned elsewhere
const transformations; // Assigned elsewhere
const load; // Assigned elsewhere
(function doEtlTask(self) {
    var payload = [];

    // Extract next batch
    batch = batches.next();
    if (!batch.done) {
        batch = batch.value;
        self.tasks[key]._itemsExtracted += batch.length;
        
        // Do transformations on each batch item
        batch.forEach(function(item) {
            transformations.forEach(function(t) {
                item = t.transform(item);
            });
            if (item && item !== {}) payload.push(item);
        });

        // Load to destination
        load.batch(payload)
            .then(function(msg) {
                doEtlTask(self);
            });
    } else {
        // .. Handle end of task execution
    };
})(this); // Bound to TaskManager instance context
\end{minted}

\section{nETL Modules}
\label{netl-modules}

\subsection{Module Authoring and Loading}
\label{netl-module-loading}
\begin{minted}{text}
// Load the module into memory
memoryObject[userModule.name] = userModule.exe;
// Invoke the module's closure
var loadedModule = memoryObject[userModule.Name].call(userModule);
// Genrate batch from extraction module
var batch = loadedModule.getNext()
// Do transformations on batch
batch = loadedModule.transform(batch);
// Load transformed batch
load.batch(batch).then(function(msg) {}).catch(function(msg) {});
// An example userModule (an extraction module)
userModule = (function() {
    function exe(configurationObj) {
        function getNext() { /* ... */};
        return {
            getNext: getNext
        };
    };
    return {
        name: "MODULE_NAME",
        exe: exe
    };
})();
\end{minted}


\subsection{Extraction Modules}
\subsubsection{FLATFILE}
\label{netl-extract-flatfile}
\begin{minted}{text}
'use strict';
const fs = require('fs');
const path = require('path');
/**
 * Configuration example
 * "Extraction": {
 *     "Name": "FLATFILE",
 *     "path": "....csv",
 *     "skipHeaderRows": 1,
 *     "bufferSize": 65536,
 *     "batchSize": 10000,
 *     "startFrom": 0,
 *     "afterTaskRunCBs": []
 * }
 */
function FLATFILE() {
    const options = this;
    const skipItems = options.skipHeaderRows || 0;
    const LF = 10;
    const CR = 13;
    var bufferSize = options.bufferSize || 64 * 1024;
    var position = options.startFrom || 0;
    var lines = _readLines();
    var currentLine = -1;

    // Open the file to be extracted
    var fd;
    var fileStats;
    var filesize;
    var filepath;
    try {
        // Try absolute path
        try {
            filepath = path.normalize(options.path)
            fd = fs.openSync(filepath, 'r');
        } catch (error) {
            // Try relative path
            try {
                filepath = path.normalize(path.join(__dirname, options.path));
                fd = fs.openSync(filepath, 'r');
            } catch (error) {
                throw new Error("File at " + options.path + " cannot be found. Please check your configuration");
            };
        };
        fileStats = fs.fstatSync(fd);
        filesize = fileStats.size;
    } catch (error) {
        throw new Error(error.message);
    };

    /* PRIVATE method */
    function* _readLines() {
        var lineBuffer;
        while (position < filesize) {
            let remaining = filesize - position;
            if (remaining < bufferSize) bufferSize = remaining;
            let chunk = new Buffer(bufferSize);
            let bytesRead = fs.readSync(fd, chunk, 0, bufferSize, position);
            let curpos = 0;
            let startpos = 0;
            let lastbyte = null;
            let curbyte;
            while (curpos < bytesRead) {
                curbyte = chunk[curpos];
                if (curbyte === LF && lastbyte !== CR || curbyte === CR && curpos < bytesRead - 1) {
                    yield _concat(lineBuffer, chunk.slice(startpos, curpos));
                    lineBuffer = undefined;
                    startpos = curpos + 1;
                    if (curbyte === CR && chunk[curpos + 1] === LF) {
                        startpos++;
                        curpos++;
                    };
                } else if (curbyte === CR && curpos >= bytesRead - 1) {
                    lastbyte = curbyte;
                };
                curpos++;
            };
            position += bytesRead;
            if (startpos < bytesRead) {
                lineBuffer = _concat(lineBuffer, chunk.slice(startpos, bytesRead));
            };
        };
        // dump what ever is left in the buffer
        if (Buffer.isBuffer(lineBuffer)) yield lineBuffer;
    };

    /* PRIVATE method */
    function _concat(buffOne, buffTwo) {
        if (!buffOne) return buffTwo;
        if (!buffTwo) return buffOne;

        let newLength = buffOne.length + buffTwo.length;
        return Buffer.concat([buffOne, buffTwo], newLength);
    };

    /* PUBLIC method */
    function getNext() {
        var nextLine = lines.next();
        currentLine++;
        while (currentLine <= skipItems - 1) {
            nextLine = lines.next();
            currentLine++;
        };
        if (!nextLine.done) {
            nextLine.value = nextLine.value.toString();
        };
        return nextLine;
    };

    /* API */
    return {
        getNext: getNext
    };
};
module.exports = {
    name: "FLATFILE",
    exe: FLATFILE
};
\end{minted}

% Loads

\subsection{Load Modules}
\subsubsection{COUCHDB}
\label{netl-load-couchdb}
\begin{minted}{text}
'use strict';
const request = require('request');
/**
 * Configuration example:
 * "Load": {
 *     "Name": "COUCHDB",
 *     "username": "admin",
 *     "password": "password",
 *     "server": "localhost",
 *     "port": 5984,
 *     "ssl": false,
 *     "database": "msc",
 *     "afterTaskRunCBs": []
 * }
 */
function COUCHDB() {
    const options = this;
    const username = options.username || null;
    const password = options.password || null;
    const server = options.server || null;
    const protocol = (options.ssl) ? 'https' : 'http';
    const port = (options.port) ? (typeof options.port === 'number') ? options.port : 80 : 80;
    const db = options.database || null;
    const address = protocol + '://' + username + ':' + password + '@' + server + ':' + port + '/' + db;
    function batch(data) {
        var postData = { docs: data };
        var endpoint = '/_bulk_docs';
        var url = address + endpoint;
        return new Promise(function(fulfill, reject) {
            try {
                request({
                    uri: url,
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify(postData)
                }, function(err, res, body) {
                    var msg;
                    if (err) {
                        reject(err);
                    } else if (res.statusCode !== 201) {
                        reject(res.statusCode);
                    } else {
                        fulfill(res.statusCode);
                    };
                });
            } catch (e) {
                reject(e);
            };
        });
    };
    return {
        batch: batch
    };
};
module.exports = {
    name: 'COUCHDB',
    exe: COUCHDB
};
\end{minted}

% Transformations
\subsection{Transformation Modules}
\subsubsection{TEXT\_LINE\_TO\_OBJ}
\label{netl-trans-text-line-to-obj}
\begin{minted}{text}
'use strict';
const Readable = require('stream').Readable;
const csvParser = require('csv-parse/lib/sync');


/**
 * Using RFC 4180 CSV definition
 * Configuration example:
 * {
 *     "Name": "TEXT_LINE_TO_OBJ",
 *     "attributeNames": "<list of CSV headers>",
 *     "delimiter": ",",
 *     "textQualifier": "\"",
 *     "escapeChar": "\\",
 *     "afterTaskRunCBs": []
 * }
 */
function TEXT_LINE_TO_OBJ() {
    const t = this;
    const parseOptions = {
        auto_parse: true,
        auto_parse_date: true,
        columns: null,
        comment: '',
        delimiter: t.delimiter,
        escape: t.escapeChar,
        from: 0,
        to: 1,
        ltrim: true,
        rtrim: true,
        max_limit_on_data_read: 128000,
        quote: t.textQualifier,
        relax: true,
        relax_column_count: false,
        skip_empty_lines: true,
        skip_lines_with_empty_values: true
    };
    const keys = csvParser(t.attributeNames, parseOptions)[0];

    function transform(line) {
        var values = csvParser(line, parseOptions)[0];
        var obj = Object.create(null);
        keys.forEach(function(el, i, arr) {
            obj[el] = values[i];
        });
        return obj;
    };

    return {
        transform: transform
    };
};

module.exports = {
    name: 'TEXT_LINE_TO_OBJ',
    exe: TEXT_LINE_TO_OBJ
};
\end{minted}

\subsubsection{FILTER}
\label{netl-trans-filter}
\begin{minted}{text}
'use strict';
/**
 * Configuration looks like this:
 * filterOn: {"key1"; [<list of allowed values>], "key2": [...], ...}
 * filtering can either be done on objects or arrays since
 * arrays 'keys' are treated as indexes
 */
function FILTER() {
    const t = this;
    const filterOn = t.filterOn;

    function transform(obj) {
        var includeThisObj = true;
        Object.keys(filterOn).forEach(function(key) {
            if (filterOn[key].indexOf(obj[key]) < 0) {
                includeThisObj = false;
            }
        });
        if (includeThisObj) return obj;
    };

    return {
        transform: transform
    };
};

module.exports = {
    name: 'FILTER',
    exe: FILTER
};
\end{minted}

\subsubsection{WHITELIST}
\label{netl-trans-whitelist}
\begin{minted}{text}
'use strict';
/**
 * Configuration example:
 * {
 *   "Name": "WHITELIST",
 *   "allowedAttributes": [
 *       "type_", "RegAcadYear", "anonIDnew", "Course", "Percent"
 *   ],
 *   "afterTaskRunCBs": []
 * } 
 */
function WHITELIST() {
    const t = this;
    var allowedAttributes = t.allowedAttributes;

    function transform(doc) {
        var newDoc = {};
        for (var attr in doc) {
            if (!doc.hasOwnProperty(attr)) continue;
            if (allowedAttributes.includes(attr)) newDoc[attr] = doc[attr];
        };
        if (Object.keys(newDoc).length !== 0) return newDoc;
    };

    return {
        transform: transform
    };
};

module.exports = {
    name: 'WHITELIST',
    exe: WHITELIST
};
\end{minted}

\subsubsection{CREATE\_OBJ\_FIELD}
\label{netl-trans-create-obj-field}
\begin{minted}{text}
'use strict';
/**
 * Configuration example:
 * {
 *     "Name": "CREATE_OBJ_FIELD",
 *     "newAttributes": [
 *         ["type_", "courseGrade"]
 *     ],
 *     "afterTaskRunCBs": []
 * },
 */
function CREATE_OBJ_FIELD() {
    const t = this;

    function transform(obj) {
        if (obj === {} || !obj) return;
        const transformedObj = JSON.parse(JSON.stringify(obj));
        t.newAttributes.forEach(function(attr) {
            // Throw error if key already exists
            if (transformedObj.hasOwnProperty(attr[0])) {
                throw new Error("New property not allowed!");
            }
            transformedObj[attr[0]] = attr[1]
        });
        return transformedObj;
    };

    return {
        transform: transform
    };
};

module.exports = {
    name: 'CREATE_OBJ_FIELD',
    exe: CREATE_OBJ_FIELD
};
\end{minted}