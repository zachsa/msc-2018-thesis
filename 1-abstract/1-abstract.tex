In the context of \textit{Educational Data Mining} it is shown that xxx xxx  by joining datasets of student demographic and benchmarking information, university grades, and LMS (learning management software) usage. An example of how data aggregation can be achieved using CouchDB's \textit{MapReduce} implementation is shown with reference to the built-in \textit{\_stats} function as the reduce component in creating a \textit{MapReduce} view. Querying and aggregating data in CouchDB is achieved by creating B+tree indexes derived from the main database files. These indexes are optimized for incremental updates, meaning that CouchDB is a suitable tool for near realtime analysis of huge databases dispersed across many, many servers.

In support of this analysis a configurable ETL tool was conceptualized to asynchronously extract, transform and load data from large flat files into CouchDB iteratively and in batches. This tool, called \textit{nETL} was implemented in JavaScript primarily because this language is asynchronous by default, but also because it makes an API available for easily generating iterators to allow batch processing of large files.