\section{Future Work}
As mentioned previously, CouchDB views are optimized when using built-in reduce functions, with custom reduce functions performing most poorly on Windows machines. As this project was completed on the Windows OS, the analysis on how best to aggregate the different entities was confined to using just the built-in reduce functions.

Using custom reduce functions would greatly increase the number of possible methods of joining entities since output of map functions would not be constrained to match the contracts of the built-in functions. Such an approach shouldn't be discounted considering that reduce function calculation (whether custom or built-in) represents a small percentage of computer resources used in view calculations overall \cite{slack1Nov}. And in any case, a system that utilizes CouchDB is likely to be based on a cluster of Linux machines rather than a single Windows machine.

It would be worth investigating the benefit that clustering CoucDB across many separate nodes. Although the database was sharded (CouchDB is configured to use 8 shards by default) and so processed data in parallel (across 2 physical cores), it is likely that deploying shards to separate servers would greatly increase performance and decrease indexing time. CouchDB disperses documents evenly across shards in a random fashion, suggesting that the workload of indexing the documents would be distributed evenly across all the shards of the database \cite{slack7Nov}. It is likely sharding would benefit large datasets, but not smaller datasets since the cost of network interactions would also increase if shards were distributed across separate nodes.

There is also scope to develop a GUI for the \textit{nETL} application and launch a competitor to Microsoft's SSDT that is browser based and JSON-based.