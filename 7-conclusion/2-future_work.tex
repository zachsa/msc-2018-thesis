\section{Future work}
This project's scope is limited to a single approach to document joining, to working with a relatively small amount of data and and working in an environment that CouchDB is not necessarily targeted at. Aside from the fact that more case studies using CouchDB will greatly increase insight into how to use CouchDB more generally, there is scope for further development of the research presented here.

As mentioned previously, CouchDB views are optimized when using built-in reduce functions, with custom reduce functions performing most poorly on Windows machines. As this project was completed on the Windows OS, the analysis on how best to aggregate the different entities (grades, demographics and events) was confined to using just the \textit{\_stats} built in reduce function. The output of this function overlaps output of the other two built-in reduce functions (\textit{\_count}, \textit{\_sum} (and provides additional metrics). Using custom reduce functions would greatly increase the number of possible methods of joining entities since output of map functions would not be constrained to match the contracts of the built-in functions. Such an approach shouldn't be discounted considering that on platforms other than Windows, reduce function calculation (whether custom or built-in) represents a small percentage of computer resources used in view calculations overall (see appendix \ref{slack-1-nov}). And in any case, a system that utilizes CouchDB is likely to be based on a cluster of Linux machines rather than a single Windows machine.

Since, for this project, CouchDB was configured to run on a single Windows machine for this project, it would be worth investigating the benefit that clustering CoucDB across many separate nodes provides. Although the database was sharded (CouchDB is configured to use 8 shards by default) and so processed data in parallel, it is likely that deploying shards to separate servers would greatly increase performance and decrease indexing time. CouchDB disperses documents evenly across shards in a random fashion, suggesting that the workload of indexing the documents would be distributed evenly across all the shards of the database (see \ref{slack-7-nov}). It is likely that the larger benefits would be seen with increasing data sizes since there is first the cost of network interactions to overcome if shards were distributed across separate nodes.

There is also scope to develop a user interface for the \textit{nETL} application and launch a competitor to Microsoft's SSDT that is browser based and JSON-based.