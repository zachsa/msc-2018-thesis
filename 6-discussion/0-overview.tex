This project was initially envisioned as means of exploring MapReduce as an alternative to RDBMSs when working with relational datasets. Performing `relational-like' data operations in CouchDB requires a high level overhaul of the entire data handling process as compared to when working with RDBMSs. Such a process has been demonstrated in this project along with some insight into techniques on how to best profile students using admissions data in terms of the CSC1015F course.

\section{Working with relational data}
Unlike SQL, which is a standard implemented in different software applications (with variation across these applications), MapReduce is a concept without any standard means of implementation. As such, although it's possible to replicate much (or all) SQL operations conceptually using MapReduce, actual MapReduce implementations are limited in terms of what relational operations can be performed according to structured domain in which they are applied.

CouchDB uses MapReduce as a deterministic means of producing indices using parallel processing; MapReduce is implemented in terms of index requirements rather than as a means of performing relational operations on datasets. As such, performing relational operations on datasets using CouchDB's implementation of MapReduce is impossible. But relational operations are possible using a software stack that includes CouchDB; such is the mindset of working with NoSQL databases instead of RDBMSs. In the context of this project, a means of using CouchDB as part of a software stack geared for processing relational data is demonstrated - such an approach can be described in terms of three steps:

\begin{enumerate}
    \item ETL processes should be designed with the data domain in mind, and cleaning, filtering, etc. should be handled appropriately
    \item MapReduce is used as a means of normalizing entity representation and creating indices ordered by compound keys
    \item Joins and aggregations are performed via iterating over ordered indices
\end{enumerate}

Although indices may be time-consuming to calculate initially, scanning b+trees is very efficient and so data retrieval from CouchDB is fast once indexed. And since indices are updated incrementally, joins performed via index scans are also very efficient. In this sense the relational capabilities of CouchDB far exceed RDBMSs when huge datasets are in play; selections can be performed prior to indexing (in either ETL or mapping functions), and joins can be performed on tiny subsets of data. Using an RDBMS, on the other hand, one would need to scan whole datasets to perform similar joins. However, working with relational datasets that aren't huge is certainly much easier in any database other than CouchDB!