\subsection{left join}
Using compound keys to implement a join, which requires emitting the same value for multiple keys for some entities























I took an iterative approach to joining entities, with each iteration introducing additional complexity to the join requirements and introducing additional data-load. With an iterative approach I was able to identify key performance considerations when working with the tech stack described within this thesis. Looking at two entities: \textit{Grades} and \textit{Demographics} with the aim of correlating student benchmarks with the results of a specific course \textit{CSC1015F}. Student results from the \textit{CSC1015F} were iteratively joined with an increasing number of the available benchmarks to measure the indexing time of creating the joined datasets. In all cases computing time was conducted on the same PC, with indexing time retrieved from the logs, both for the \textit{nETL} application and the \textit{CouchDB} application. Logs were read using the useful \textit{grep} tool available via the Ubuntu 16.04.x shell.

CouchDB indexing time was calculated via retrieving the latest logs for a particular indexing job using GREP (add ref), and the getting the difference between the smallest and largest dates. This is because shards finish at different times and so I want the start of the first shard and the end of the last shard in terms of indexing.

In preparation of this assessment \textit{nETL} was configured to process all the cohort demographic data from 2016,2015,2014 and course grade data from 2016, 2015, 2014. This includes 2 CSVs (available on request) that formed the basis for all iterative analyses. The CSVs are listed here:

\begin{enumerate}
    \item \textit{FU-CombinedGrades-2016Reg.csv}
    \item \textit{CombinedGrades.csv}
\end{enumerate}



\subsection{iteration 1: \textit{CSC1015F} result vs English Gr12 result}
Filtering was applied to the demographic data to load only students who had taken \textit{CSC1015F}. Because \textit{nETL}'s filter module allows for specifying attributes to filter on with a corresponding list of values to accept, and NOT (without additional coding) filter on indirect associations such as \textit{student IDs that appear in the set ...}, a list of students was manually compiled to apply the filter on comprising 1879 unique students who registered for \textit{CSC1015F} in 2016, 2015, and 2015 (36 students registered for this course in separate years). Grades were filtered to only load results from the \textit{CSC1015F} course. White-listing of attributes was then applied to create docs of the following form:

\begin{minted}{javascript}
// Demographics JSON documents
{
    "type_": "demographic",
    "anonIDnew": <number>,
    "Gr12 Eng": <grade (uncleaned)>,
    "RegAcadYear": <year>
}

// Grade JSON documents
{
    "type_": "courseGrade",
    "RegAcadYear": <year>,
    "anonIDnew": <number>,
    "Percent": <grade (uncleaned)>
}
\end{minted}

The \textit{nETL} configuration comprised two tasks run asynchronously to produce the above entities. The \textit{nETL} configuration is shown in \ref{appendix:config-i1}, with execution results of the \textit{nETL} shown in \ref{i1-results} alongside the database document summary (produced by the MapReduce index shown in \ref{appendix:dbInfo}).

\begin{table}[]
    \centering
    \caption{\textit{nETL} runtime results for I1 analysis}
    \label{i1-results}
    \begin{tabular}{lcc}
                                      & FU documents                    & Grade documents \\ \hline
        CSV lines extracted           & 12219                           & 513872          \\
        CSV lines loaded              & 1380                            & 1891            \\
        \textit{nETL} task time (sec) & 2.4                             & 31.9            \\
        CouchDB footprint             & \multicolumn{2}{c}{0.8MB}                         \\
        Year 2016 doc-count           & 524                             & 738             \\
        Year 2015 doc-count           & 460                             & 618             \\
        Year 2014 doc-count           & 396                             & 535             \\
        View calculation time (sec)   & \multicolumn{2}{c}{\textless 5}                   \\
    \end{tabular}
\end{table}

The MapReduce join in the context of this analysis should be performed on key tuples of <year, studentId>, with a result output of <\textit{CSC1015F} \%, Gr12Eng \%>. The design document to achieve this format is shown in \ref{appendix:ddoc-i1}. The Map function includes logic to translate grade symbols to percentages; since the reduce phase (the built-in \_stats function in this case) requires that value-output of the Map function be an array of numbers. The list of numbers in the output in this case has reserved indexes for output of each document type. In this case each document has 1 output and there are 2 documents - so the output for this MapReduce task is a \textit{key:value} tuple of the form:

\begin{minted}{javascript}
[[<year>, <student ID>]: [<course output int>, <demographic output int>]],
[[2016, 1987]: [78, 85]],
[[2016, 1990]: [67, 76]],
etc
\end{minted}

In this case the student with an ID of 1987 achieved a course grade of 78\% and a Grade 12 English grade of 85\%.


Results are shown in the graphs in Fig TODO.

\subsection{iteration 2: \textit{CSC1015F} result vs all (8) demographic markers}
Similar to \textit{Iteration 1}, filtering was applied to the demographic data to load only students who had taken \textit{CSC1015F} by manually selecting student IDs and configuring the filter to allow rows of only those student IDs into the database. Grade-rows from the \textit{CSC1015F} course and white-listing of attributes was then applied to create documents with the desirable attributes only. This iteration used all the markers from the demographic information:

\begin{enumerate}
    \item Gr12 Eng \%
    \item Gr12 Sci \%
    \item Gr12 Mth \%
    \item Gr12 Mth Lit \%
    \item Gr12 Mth Adv \%
    \item NBT AL \%
    \item NBT QL \%
    \item NBT Mth \%
\end{enumerate}

\begin{minted}{javascript}
// Demographics JSON documents
{
    "type_": "demographic",
    "anonIDnew": <number>,
    "Gr12 Eng": <grade (uncleaned)>,
    "Gr12 Sci": <grade (uncleaned)>,
    "Gr12 Mth": <grade (uncleaned)>,
    "Gr12 Mth Lit": <grade (uncleaned)>,
    "Gr12 Mth Adv": <grade (uncleaned)>,
    "NBT AL": <grade (uncleaned)>,
    "NBT QL": <grade (uncleaned)>,
    "NBT Mth": <grade (uncleaned)>,
    "RegAcadYear": <year>
}

// Grade JSON documents
{
    "type_": "courseGrade",
    "RegAcadYear": <year>,
    "anonIDnew": <number>,
    "Percent": <grade (uncleaned)>
}
\end{minted}

The Map function output in this case is a key of [<year>, <student ID>] with the value another tuple of 9 indexes (0 - 8), each index corresponding to a particular column in one of the CSVs.

Similarly to Iteration 1, \textit{nETL} was configured to run two tasks asynchronously with the configuration shown in \ref{appendix:config-i2}. Execution results are shown in \ref{i2-results}.

\begin{table}[]
    \centering
    \caption{\textit{nETL} runtime results for I2 analysis. As expected the database footprint increased slightly along with inclusion of 7 additional columns from the demographics CSV. Runtime of the \textit{nETL} task increased slightly - but that is not meaningful on a single run.}
    \label{i2-results}
    \begin{tabular}{lcc}
                             & FU documents              & Grade documents \\ \hline
        CSV lines extracted  & 12219                     & 513872          \\
        CSV lines loaded     & 1380                      & 1891            \\
        nETL task time (sec) & 2.4                       & 33.8            \\
        CouchDB footprint    & \multicolumn{2}{c}{0.9MB}                   \\
        Year 2016 doc-count  & 524                       & 738             \\
        Year 2015 doc-count  & 460                       & 618             \\
        Year 2014 doc-count  & 396                       & 535             \\
    \end{tabular}
\end{table}


\subsection{iteration 3: Introducing additional courses}
The above examples achieve the join of the demographic data and the grade data through joining on keys as output by the map task. CoucuDB allows for configuring the level at which keys are grouped when using \textit{compound-keys}. The above iterations showed key groupings in the form \textit{<year, student ID>}. With an \textit{exact} level of grouping (the default), demographic and grade data is joined on the \textit{<year, student ID>} combination and the output is grouped on that as well. With a grouping of level 1 it's possible to join the two entities on just \textit{year}, and then group on that as well - i.e. join the two datasets on the year. Though this would not be useful in practice, it is a principle worth demonstrating.

Such a grouping is only possible when all entities can output keys on which grouping can occur - i.e. both the demographic and grade data include \textit{year} and \textit{student number} fields, and so by emitting \textit{<year, student ID>} tuples from each entity allows the CouchDB MapReduce engine to group on matching tuples. The demographic entity doesn't include course information, however, so it is impossible to emit tuples of \textit{<year, student ID, course ID>} on which the entities can be grouped from within the map function using information accessible via the 'doc' argument. Within the Map function it is possible to included information that allows for emitting key values that would not otherwise be accessible; this is not a clean approach to data querying since the query itself needs to contain information on the databases state.

Using built-in reduce functions (\_sum or \_stats), where the values-output of the map function must be numbers, there are 3 different ways incorporating courses into the join as discussed in iteration 1 and iteration 2. These are:

\begin{enumerate}
    \item Increase the size of the output tuple to incorporate an index for each possible grade (but that would require a tuple of around 5000 indexes, and a switch statement with 5000 cases)
    \item Courses could be mapped to numbers via a hashing function during map reduce calculation, and then mapped back to course codes at a later stage
    \item The demographic entity could be emitted for every possible grade value
\end{enumerate}

The 3rd option in this case is tested as the most feasible. It requires the lease amount of programming, data scrubbing, etc and also is a decent approximation of a an outer join in which rows are often duplicated in on of the entities. Increasing the number of courses involved in the query greatly increases the size of the list of students that are being included, however. As such a manual filter is no longer feasible - a list of 79 849 student numbers is both ungainly and almost a 3rd of all the student numbers entire the grades dataset in any case. As such the filter on student numbers was removed.

\begin{table}[]
    \centering
    \caption{\textit{nETL} runtime results for I3 analysis.}
    \label{i3-results}
    \begin{tabular}{lcc}
                                 & FU documents             & Grade documents \\ \hline
        CSV lines extracted      & 12219                    & 513872          \\
        CSV lines loaded         & 9874                     & 79849           \\
        nETL task time (sec)     & 3.5                      & 43.1            \\
        CouchDB footprint (MB)   & \multicolumn{2}{c}{23.2}                   \\
        CouchDB index time (sec) & \multicolumn{2}{c}{24.6}                   \\
        Index footprint (MB)     & \multicolumn{2}{c}{52.9}                   \\
        Year 2016 doc-count      & 3413                     & 28103           \\
        Year 2015 doc-count      & 3406                     & 26497           \\
        Year 2014 doc-count      & 3055                     & 25249           \\
    \end{tabular}
\end{table}

\subsection{iteration 4: Introducing the Events entity}
A quick analysis of the events dataset shows that for the 40 courses as queried in Iteration 2, there are 8 848 001 presence events for the students enrolled in these courses (events can't be joined on students)